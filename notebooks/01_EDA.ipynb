{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection - Exploratory Data Analysis\n",
    "\n",
    "This notebook explores the credit card transaction dataset to understand:\n",
    "- Data structure and quality\n",
    "- Class imbalance (fraud vs legitimate)\n",
    "- Feature distributions and patterns\n",
    "- Temporal and geographic trends\n",
    "\n",
    "**Dataset:** Kaggle Credit Card Fraud Detection (simulated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data/interim')\n",
    "FIGURES_DIR = Path('../outputs/figures')\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load merged dataset\n",
    "df = pd.read_csv(DATA_DIR / 'transactions_merged.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Rows: {df.shape[0]:,}\")\n",
    "print(f\"Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names and types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last few rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column list with dtypes\n",
    "pd.DataFrame({\n",
    "    'dtype': df.dtypes,\n",
    "    'non_null': df.count(),\n",
    "    'null_count': df.isnull().sum(),\n",
    "    'unique': df.nunique()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'missing_count': missing,\n",
    "    'missing_pct': missing_pct\n",
    "}).sort_values('missing_count', ascending=False)\n",
    "\n",
    "print(\"Missing Values:\")\n",
    "print(missing_df[missing_df['missing_count'] > 0])\n",
    "\n",
    "if missing.sum() == 0:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicates}\")\n",
    "\n",
    "# Duplicate transaction IDs\n",
    "dup_trans = df['trans_num'].duplicated().sum()\n",
    "print(f\"Duplicate transaction IDs: {dup_trans}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Target Analysis (Class Imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud distribution\n",
    "fraud_counts = df['is_fraud'].value_counts()\n",
    "fraud_pct = df['is_fraud'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(f\"  Legitimate (0): {fraud_counts[0]:,} ({fraud_pct[0]:.2f}%)\")\n",
    "print(f\"  Fraudulent (1): {fraud_counts[1]:,} ({fraud_pct[1]:.2f}%)\")\n",
    "print(f\"\\nImbalance Ratio: {fraud_counts[0]/fraud_counts[1]:.0f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class imbalance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Bar plot\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "bars = axes[0].bar(['Legitimate', 'Fraud'], fraud_counts.values, color=colors)\n",
    "axes[0].set_title('Transaction Class Distribution', fontsize=14)\n",
    "axes[0].set_ylabel('Count')\n",
    "for bar, count in zip(bars, fraud_counts.values):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "                 f'{count:,}', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(fraud_counts.values, labels=['Legitimate', 'Fraud'],\n",
    "            autopct='%1.2f%%', colors=colors, explode=[0, 0.1],\n",
    "            shadow=True, startangle=90)\n",
    "axes[1].set_title('Fraud Percentage', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insight:** Severe class imbalance (~99.5% legitimate, ~0.5% fraud)\n",
    "- Accuracy is NOT a suitable metric\n",
    "- Need: SMOTE, class weights, PR-AUC metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction amount distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Overall distribution\n",
    "axes[0, 0].hist(df['amt'], bins=50, color='steelblue', edgecolor='white')\n",
    "axes[0, 0].set_title('Transaction Amount Distribution')\n",
    "axes[0, 0].set_xlabel('Amount ($)')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# Log scale\n",
    "axes[0, 1].hist(np.log1p(df['amt']), bins=50, color='steelblue', edgecolor='white')\n",
    "axes[0, 1].set_title('Log Transaction Amount')\n",
    "axes[0, 1].set_xlabel('Log(Amount + 1)')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "\n",
    "# By fraud status (boxplot)\n",
    "df.boxplot(column='amt', by='is_fraud', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Amount by Fraud Status')\n",
    "axes[1, 0].set_xlabel('Is Fraud')\n",
    "axes[1, 0].set_ylabel('Amount ($)')\n",
    "plt.suptitle('')\n",
    "\n",
    "# Density by fraud status\n",
    "for fraud_val, color, label in [(0, '#2ecc71', 'Legitimate'), (1, '#e74c3c', 'Fraud')]:\n",
    "    subset = df[df['is_fraud'] == fraud_val]['amt']\n",
    "    axes[1, 1].hist(np.log1p(subset), bins=50, alpha=0.6, color=color, label=label, density=True)\n",
    "axes[1, 1].set_title('Amount Distribution by Fraud Status')\n",
    "axes[1, 1].set_xlabel('Log(Amount + 1)')\n",
    "axes[1, 1].set_ylabel('Density')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'amount_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount statistics by fraud status\n",
    "df.groupby('is_fraud')['amt'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction categories\n",
    "print(f\"Number of categories: {df['category'].nunique()}\")\n",
    "print(f\"\\nCategories:\")\n",
    "print(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud rate by category\n",
    "category_fraud = df.groupby('category').agg(\n",
    "    total=('is_fraud', 'count'),\n",
    "    fraud_count=('is_fraud', 'sum'),\n",
    "    fraud_rate=('is_fraud', 'mean')\n",
    ").sort_values('fraud_rate', ascending=False)\n",
    "\n",
    "category_fraud['fraud_rate_pct'] = category_fraud['fraud_rate'] * 100\n",
    "print(category_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud rate by category\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Transaction count by category\n",
    "cat_counts = df['category'].value_counts()\n",
    "axes[0].barh(cat_counts.index, cat_counts.values, color='steelblue')\n",
    "axes[0].set_title('Transactions by Category')\n",
    "axes[0].set_xlabel('Count')\n",
    "\n",
    "# Fraud rate by category\n",
    "fraud_rates = category_fraud['fraud_rate_pct'].sort_values(ascending=True)\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(fraud_rates)))\n",
    "axes[1].barh(fraud_rates.index, fraud_rates.values, color=colors)\n",
    "axes[1].set_title('Fraud Rate by Category (%)')\n",
    "axes[1].set_xlabel('Fraud Rate (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'category_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender distribution\n",
    "print(\"Gender Distribution:\")\n",
    "print(df['gender'].value_counts())\n",
    "print(f\"\\nFraud rate by gender:\")\n",
    "print(df.groupby('gender')['is_fraud'].mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Temporal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse datetime\n",
    "df['trans_datetime'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df['trans_hour'] = df['trans_datetime'].dt.hour\n",
    "df['trans_day'] = df['trans_datetime'].dt.day\n",
    "df['trans_month'] = df['trans_datetime'].dt.month\n",
    "df['trans_dayofweek'] = df['trans_datetime'].dt.dayofweek\n",
    "df['trans_year'] = df['trans_datetime'].dt.year\n",
    "\n",
    "print(f\"Date range: {df['trans_datetime'].min()} to {df['trans_datetime'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Transactions by hour\n",
    "hourly_counts = df.groupby('trans_hour').size()\n",
    "axes[0, 0].bar(hourly_counts.index, hourly_counts.values, color='steelblue')\n",
    "axes[0, 0].set_title('Transactions by Hour')\n",
    "axes[0, 0].set_xlabel('Hour of Day')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# Fraud rate by hour\n",
    "hourly_fraud = df.groupby('trans_hour')['is_fraud'].mean() * 100\n",
    "axes[0, 1].plot(hourly_fraud.index, hourly_fraud.values, 'ro-', linewidth=2, markersize=6)\n",
    "axes[0, 1].set_title('Fraud Rate by Hour (%)')\n",
    "axes[0, 1].set_xlabel('Hour of Day')\n",
    "axes[0, 1].set_ylabel('Fraud Rate (%)')\n",
    "axes[0, 1].axhline(y=df['is_fraud'].mean()*100, color='gray', linestyle='--', label='Overall')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Day of week\n",
    "dow_labels = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "dow_fraud = df.groupby('trans_dayofweek')['is_fraud'].mean() * 100\n",
    "axes[1, 0].bar(dow_labels, dow_fraud.values, color='coral')\n",
    "axes[1, 0].set_title('Fraud Rate by Day of Week')\n",
    "axes[1, 0].set_ylabel('Fraud Rate (%)')\n",
    "\n",
    "# Monthly trend\n",
    "monthly = df.groupby(['trans_year', 'trans_month'])['is_fraud'].mean() * 100\n",
    "monthly = monthly.reset_index()\n",
    "monthly['period'] = monthly['trans_year'].astype(str) + '-' + monthly['trans_month'].astype(str).str.zfill(2)\n",
    "axes[1, 1].plot(range(len(monthly)), monthly['is_fraud'].values, 'b-o', markersize=4)\n",
    "axes[1, 1].set_title('Monthly Fraud Rate Trend')\n",
    "axes[1, 1].set_xlabel('Month')\n",
    "axes[1, 1].set_ylabel('Fraud Rate (%)')\n",
    "axes[1, 1].set_xticks(range(0, len(monthly), 3))\n",
    "axes[1, 1].set_xticklabels(monthly['period'].iloc[::3], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'temporal_patterns.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Insight:** Fraud rates vary by time\n",
    "- Higher fraud rates during late night/early morning hours\n",
    "- Time-based features will be useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance between customer and merchant\n",
    "df['distance'] = np.sqrt(\n",
    "    (df['lat'] - df['merch_lat'])**2 + \n",
    "    (df['long'] - df['merch_long'])**2\n",
    ")\n",
    "\n",
    "print(\"Distance statistics:\")\n",
    "print(df['distance'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance by fraud status\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Boxplot\n",
    "df.boxplot(column='distance', by='is_fraud', ax=axes[0])\n",
    "axes[0].set_title('Customer-Merchant Distance by Fraud Status')\n",
    "axes[0].set_xlabel('Is Fraud')\n",
    "axes[0].set_ylabel('Distance')\n",
    "plt.suptitle('')\n",
    "\n",
    "# Density\n",
    "for fraud_val, color, label in [(0, '#2ecc71', 'Legitimate'), (1, '#e74c3c', 'Fraud')]:\n",
    "    subset = df[df['is_fraud'] == fraud_val]['distance']\n",
    "    axes[1].hist(subset, bins=50, alpha=0.6, color=color, label=label, density=True)\n",
    "axes[1].set_title('Distance Distribution by Fraud Status')\n",
    "axes[1].set_xlabel('Distance')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'geographic_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance stats by fraud\n",
    "print(\"Distance by fraud status:\")\n",
    "print(df.groupby('is_fraud')['distance'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns for correlation\n",
    "numerical_cols = ['amt', 'lat', 'long', 'city_pop', 'merch_lat', 'merch_long', \n",
    "                  'trans_hour', 'trans_dayofweek', 'distance', 'is_fraud']\n",
    "\n",
    "corr_matrix = df[numerical_cols].corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0,\n",
    "            fmt='.2f', square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'correlation_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target\n",
    "target_corr = df[numerical_cols].corr()['is_fraud'].drop('is_fraud').sort_values(key=abs, ascending=False)\n",
    "print(\"Correlation with Fraud:\")\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Insights Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "- **1.85M transactions** from 2019-2020\n",
    "- **23 features** including transaction, customer, and merchant info\n",
    "- **No missing values**\n",
    "\n",
    "### Class Imbalance\n",
    "- **~99.5% legitimate, ~0.5% fraud** (ratio ~190:1)\n",
    "- Need specialized handling: SMOTE, class weights\n",
    "- Use PR-AUC, not accuracy\n",
    "\n",
    "### Feature Insights\n",
    "1. **Amount:** Fraudulent transactions show different amount patterns\n",
    "2. **Category:** Some categories have higher fraud rates (shopping_net, misc_net)\n",
    "3. **Time:** Higher fraud rates at night (00:00-06:00)\n",
    "4. **Distance:** Customer-merchant distance may indicate fraud\n",
    "\n",
    "### Feature Engineering Ideas\n",
    "- Time features: hour, day, weekend, is_night\n",
    "- Amount: log transform\n",
    "- Geographic: customer-merchant distance\n",
    "- Category encoding: target encoding for fraud rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed dataframe with new features for later use\n",
    "print(f\"Final dataframe shape: {df.shape}\")\n",
    "print(f\"\\nNew columns added: trans_datetime, trans_hour, trans_day, trans_month, trans_dayofweek, trans_year, distance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
